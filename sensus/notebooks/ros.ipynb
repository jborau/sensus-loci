{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2023-03-30 23:14:06,059 - instantiator - Created a temporary directory at /tmp/tmpyq38semr\n",
      "INFO - 2023-03-30 23:14:06,059 - instantiator - Writing /tmp/tmpyq38semr/_remote_module_non_scriptable.py\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Open3D INFO] Resetting default logger to print to terminal.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "import sensus\n",
    "\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "\n",
    "from sensus.utils.data_converter import pc2pc_object\n",
    "from open3d.web_visualizer import draw\n",
    "from mmdetection3d import data, demo, configs, checkpoints\n",
    "from sensus import configs as sensus_configs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read pickle file lidar.pickle from data directory\n",
    "with open(os.path.join(sensus.__path__[0], 'data/lidar.pickle'), 'rb') as f:\n",
    "    lidar_pickle = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_buffer = np.frombuffer(lidar_pickle.data,\n",
    "                    dtype=[('x', np.float32), ('y', np.float32), ('z', np.float32), ('intensity', np.float32)],\n",
    "                    count=lidar_pickle.width*lidar_pickle.height, offset=0)\n",
    "pc_ros = pc_buffer.view(dtype=np.float32).reshape(pc_buffer.shape[0], -1)\n",
    "pc_ros[:, 2] = pc_ros[:, 2] + 6"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmdet3d.apis import inference_detector, init_model\n",
    "from mmdet3d.utils import register_all_modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: /home/messi/alvaro/sensus-loci/mmdetection3d/checkpoints/hv_second_secfpn_6x8_80e_kitti-3d-3class_20210831_022017-ae782e87.pth\n"
     ]
    }
   ],
   "source": [
    "register_all_modules()\n",
    "model_cfg = os.path.join(sensus_configs.__path__[0],\n",
    "    'second/second_hv_secfpn_8xb6-80e_kitti-3d-3class-ros.py')\n",
    "checkpoint_path = os.path.join(checkpoints.__path__[0],\n",
    "    'hv_second_secfpn_6x8_80e_kitti-3d-3class_20210831_022017-ae782e87.pth')\n",
    "device = 'cuda:0'\n",
    "\n",
    "model = init_model(model_cfg, checkpoint_path, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[115.05504    115.06092      1.2147665    0.95542234]\n",
      "[-116.592995   -115.0505       -2.008335      0.61992574]\n"
     ]
    }
   ],
   "source": [
    "# Print the max and min values of each column in the point cloud\n",
    "print(np.max(pc_ros, axis=0))\n",
    "print(np.min(pc_ros, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROS\n",
    "pc_object_ros, _ = pc2pc_object(pc_ros.flatten(), model.cfg.test_pipeline)\n",
    "result_ros, _ = inference_detector(model, pc_object_ros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Det3DDataSample(\n",
       "\n",
       "    META INFORMATION\n",
       "    pcd_rotation: tensor([[1., 0., 0.],\n",
       "                [-0., 1., 0.],\n",
       "                [0., 0., 1.]])\n",
       "    box_type_3d: <class 'mmdet3d.structures.bbox_3d.lidar_box3d.LiDARInstance3DBoxes'>\n",
       "    pcd_horizontal_flip: False\n",
       "    pcd_rotation_angle: 0.0\n",
       "    pcd_scale_factor: 1.0\n",
       "    pcd_vertical_flip: False\n",
       "    box_mode_3d: <Box3DMode.LIDAR: 0>\n",
       "    flip: False\n",
       "    pcd_trans: array([0., 0., 0.])\n",
       "    transformation_3d_flow: ['R', 'S', 'T']\n",
       "\n",
       "    DATA FIELDS\n",
       "    gt_pts_seg: <PointData(\n",
       "        \n",
       "            META INFORMATION\n",
       "        \n",
       "            DATA FIELDS\n",
       "        ) at 0x7f37183c5160>\n",
       "    gt_instances_3d: <InstanceData(\n",
       "        \n",
       "            META INFORMATION\n",
       "        \n",
       "            DATA FIELDS\n",
       "        ) at 0x7f37183c58b0>\n",
       "    pred_instances: <InstanceData(\n",
       "        \n",
       "            META INFORMATION\n",
       "        \n",
       "            DATA FIELDS\n",
       "        ) at 0x7f36d39ecca0>\n",
       "    gt_instances: <InstanceData(\n",
       "        \n",
       "            META INFORMATION\n",
       "        \n",
       "            DATA FIELDS\n",
       "        ) at 0x7f36d3999ee0>\n",
       "    pred_instances_3d: <InstanceData(\n",
       "        \n",
       "            META INFORMATION\n",
       "        \n",
       "            DATA FIELDS\n",
       "            scores_3d: tensor([0.3287, 0.3229, 0.2763, 0.2711, 0.2693, 0.2589, 0.2410, 0.2216, 0.2011,\n",
       "                        0.1959, 0.1933, 0.1926, 0.1762, 0.1760, 0.1729, 0.1714, 0.1669, 0.1666],\n",
       "                       device='cuda:0')\n",
       "            bboxes_3d: LiDARInstance3DBoxes(\n",
       "                    tensor([[  1.6682, -37.9861,  -2.6241,   4.3703,   1.7161,   1.5333,   3.2115],\n",
       "                        [  0.4471,  23.5651,  -2.7133,   4.2763,   1.6689,   1.5844,  -1.5486],\n",
       "                        [ 66.7484, -37.9560,  -2.6043,   4.2618,   1.6901,   1.5347,   2.6354],\n",
       "                        [ 64.0491, -29.3706,  -2.6038,   4.5148,   1.6910,   1.5218,   4.3003],\n",
       "                        [ 59.8636,  37.4965,  -2.5408,   4.4287,   1.7143,   1.5376,   2.0700],\n",
       "                        [ 65.4579, -25.9227,  -2.3259,   4.1568,   1.6307,   1.4564,   2.8197],\n",
       "                        [  1.5115,  38.0660,  -2.7265,   4.1277,   1.6456,   1.5130,   3.0918],\n",
       "                        [  0.4457, -24.9556,  -2.4891,   4.4855,   1.6773,   1.5584,   1.5373],\n",
       "                        [ 66.8613, -20.3428,  -2.5316,   4.1281,   1.6367,   1.4983,   4.3373],\n",
       "                        [ 70.0768,  -8.6076,  -2.4863,   3.9550,   1.6057,   1.5017,   4.5547],\n",
       "                        [ 67.8440, -35.8827,  -2.4773,   4.2053,   1.6244,   1.4792,   2.7898],\n",
       "                        [ 63.2876, -33.6338,  -2.4852,   4.1945,   1.6562,   1.4963,   2.6599],\n",
       "                        [ 34.3747, -15.4040,  -0.8330,   4.2352,   1.6472,   1.5045,   2.8870],\n",
       "                        [ 58.9799, -23.8835,  -2.5292,   4.3683,   1.6999,   1.4977,   2.9430],\n",
       "                        [ 68.7469, -15.8206,  -2.5538,   4.5310,   1.6784,   1.5144,   4.4730],\n",
       "                        [  1.8188, -34.2937,  -2.6546,   4.2469,   1.6146,   1.4301,   3.2200],\n",
       "                        [ 60.7744,  26.4245,  -2.6090,   4.8026,   1.7432,   1.5551,   1.9572],\n",
       "                        [ 56.6543, -35.5691,  -2.3679,   4.1845,   1.6281,   1.4994,   2.5852]],\n",
       "                       device='cuda:0'))\n",
       "            labels_3d: tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
       "        ) at 0x7f36d3999c40>\n",
       "    eval_ann_info: None\n",
       ") at 0x7f37183c5fd0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_ros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z + 5\n",
    "52.1288, -30.7273,  -2.8131,   4.2216,   1.7148,   1.5176,   2.8515\n",
    "# z + 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Det3DDataSample(\n",
       "\n",
       "    META INFORMATION\n",
       "    pcd_rotation: tensor([[1., 0., 0.],\n",
       "                [-0., 1., 0.],\n",
       "                [0., 0., 1.]])\n",
       "    box_type_3d: <class 'mmdet3d.structures.bbox_3d.lidar_box3d.LiDARInstance3DBoxes'>\n",
       "    pcd_rotation_angle: 0.0\n",
       "    pcd_horizontal_flip: False\n",
       "    box_mode_3d: <Box3DMode.LIDAR: 0>\n",
       "    pcd_trans: array([0., 0., 0.])\n",
       "    pcd_vertical_flip: False\n",
       "    transformation_3d_flow: ['R', 'S', 'T']\n",
       "    pcd_scale_factor: 1.0\n",
       "    flip: False\n",
       "\n",
       "    DATA FIELDS\n",
       "    pred_instances: <InstanceData(\n",
       "        \n",
       "            META INFORMATION\n",
       "        \n",
       "            DATA FIELDS\n",
       "        ) at 0x7fda4b377d90>\n",
       "    gt_pts_seg: <PointData(\n",
       "        \n",
       "            META INFORMATION\n",
       "        \n",
       "            DATA FIELDS\n",
       "        ) at 0x7fda4b2c7730>\n",
       "    gt_instances_3d: <InstanceData(\n",
       "        \n",
       "            META INFORMATION\n",
       "        \n",
       "            DATA FIELDS\n",
       "        ) at 0x7fda4b2c73d0>\n",
       "    pred_instances_3d: <InstanceData(\n",
       "        \n",
       "            META INFORMATION\n",
       "        \n",
       "            DATA FIELDS\n",
       "            scores_3d: tensor([0.1304, 0.1173, 0.3624, 0.3572, 0.9088, 0.8917, 0.8498, 0.7471, 0.7245,\n",
       "                        0.6414, 0.6307, 0.5603, 0.4316, 0.3937], device='cuda:0')\n",
       "            labels_3d: tensor([0, 0, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
       "            bboxes_3d: LiDARInstance3DBoxes(\n",
       "                    tensor([[ 3.0507e+01, -3.7150e+00, -1.2959e+00,  1.9228e+00,  5.8578e-01,\n",
       "                          1.7878e+00, -1.0387e-01],\n",
       "                        [ 3.3624e+01, -1.5408e+01, -1.4842e+00,  1.7356e+00,  5.3179e-01,\n",
       "                          1.7017e+00,  2.8747e+00],\n",
       "                        [ 3.0485e+01, -3.7236e+00, -1.2972e+00,  1.9133e+00,  6.0093e-01,\n",
       "                          1.7964e+00, -7.1814e-02],\n",
       "                        [ 3.3573e+01, -1.5382e+01, -1.3896e+00,  1.6332e+00,  5.3116e-01,\n",
       "                          1.6652e+00,  2.8745e+00],\n",
       "                        [ 1.4780e+01, -1.0779e+00, -1.4688e+00,  3.7479e+00,  1.5591e+00,\n",
       "                          1.4264e+00, -3.2357e-01],\n",
       "                        [ 8.1432e+00,  1.1950e+00, -1.5713e+00,  3.8181e+00,  1.5872e+00,\n",
       "                          1.5053e+00,  2.8483e+00],\n",
       "                        [ 6.5548e+00, -3.8596e+00, -1.7373e+00,  3.2281e+00,  1.4870e+00,\n",
       "                          1.4416e+00, -2.9311e-01],\n",
       "                        [ 3.3599e+01, -6.9979e+00, -1.1930e+00,  4.1792e+00,  1.6846e+00,\n",
       "                          1.5645e+00,  2.9612e+00],\n",
       "                        [ 2.0532e+01, -8.5866e+00, -1.7789e+00,  3.2964e+00,  1.5354e+00,\n",
       "                          1.5564e+00, -3.4729e-01],\n",
       "                        [ 3.6932e+00,  2.7057e+00, -1.5757e+00,  3.9363e+00,  1.6047e+00,\n",
       "                          1.4755e+00, -2.5535e-01],\n",
       "                        [ 2.8742e+01, -1.5891e+00, -9.8873e-01,  3.8667e+00,  1.5541e+00,\n",
       "                          1.4411e+00,  4.3777e+00],\n",
       "                        [ 2.4866e+01, -1.0196e+01, -1.7627e+00,  3.8253e+00,  1.5966e+00,\n",
       "                          1.5202e+00, -4.3520e-01],\n",
       "                        [ 5.5483e+01, -2.0294e+01, -1.2641e+00,  4.2528e+00,  1.6728e+00,\n",
       "                          1.5333e+00,  2.8051e+00],\n",
       "                        [ 4.0962e+01, -9.4771e+00, -1.2358e+00,  3.9789e+00,  1.6044e+00,\n",
       "                          1.5050e+00, -6.1777e-03]], device='cuda:0'))\n",
       "        ) at 0x7fda4b2c78b0>\n",
       "    eval_ann_info: None\n",
       "    gt_instances: <InstanceData(\n",
       "        \n",
       "            META INFORMATION\n",
       "        \n",
       "            DATA FIELDS\n",
       "        ) at 0x7fda4b2c7dc0>\n",
       ") at 0x7fda4b377340>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  1.6682, -37.9861,  -2.6241,   4.3703,   1.7161,   1.5333,   3.2115],\n",
      "       device='cuda:0')\n",
      "torch.Size([18, 7])\n"
     ]
    }
   ],
   "source": [
    "# print(result_ros.pred_instances_3d.labels_3d)\n",
    "# print(result_ros.pred_instances_3d.scores_3d)\n",
    "# print(result_ros.pred_instances_3d.bboxes_3d)\n",
    "print(result_ros.pred_instances_3d.bboxes_3d.tensor[0])\n",
    "print(result_ros.pred_instances_3d.bboxes_3d.tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'rotate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Same result after processing points (maybe processing under the hood when\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# using np.array pc)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m points \u001b[39m=\u001b[39m points\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m4\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m result, data \u001b[39m=\u001b[39m inference_detector(model, points)\n",
      "File \u001b[0;32m~/alvaro/sensus-loci/mmdetection3d/mmdet3d/apis/inference.py:158\u001b[0m, in \u001b[0;36minference_detector\u001b[0;34m(model, pcds)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    150\u001b[0m         \u001b[39m# directly use loaded point cloud\u001b[39;00m\n\u001b[1;32m    151\u001b[0m         data_ \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\n\u001b[1;32m    152\u001b[0m             points\u001b[39m=\u001b[39mpcd,\n\u001b[1;32m    153\u001b[0m             timestamp\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    156\u001b[0m             box_type_3d\u001b[39m=\u001b[39mbox_type_3d,\n\u001b[1;32m    157\u001b[0m             box_mode_3d\u001b[39m=\u001b[39mbox_mode_3d)\n\u001b[0;32m--> 158\u001b[0m     data_ \u001b[39m=\u001b[39m test_pipeline(data_)\n\u001b[1;32m    159\u001b[0m     data\u001b[39m.\u001b[39mappend(data_)\n\u001b[1;32m    161\u001b[0m collate_data \u001b[39m=\u001b[39m pseudo_collate(data)\n",
      "File \u001b[0;32m~/anaconda3/envs/sensus_1.1/lib/python3.8/site-packages/mmengine/dataset/base_dataset.py:58\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[39m\"\"\"Call function to apply transforms sequentially.\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \n\u001b[1;32m     51\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39m   dict: Transformed data.\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[0;32m---> 58\u001b[0m     data \u001b[39m=\u001b[39m t(data)\n\u001b[1;32m     59\u001b[0m     \u001b[39m# The transform will return None when it failed to load images or\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[39m# cannot find suitable augmentation parameters to augment the data.\u001b[39;00m\n\u001b[1;32m     61\u001b[0m     \u001b[39m# Here we simply return None if the transform returns None and the\u001b[39;00m\n\u001b[1;32m     62\u001b[0m     \u001b[39m# dataset will handle it by randomly selecting another data sample.\u001b[39;00m\n\u001b[1;32m     63\u001b[0m     \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/sensus_1.1/lib/python3.8/site-packages/mmcv/transforms/base.py:12\u001b[0m, in \u001b[0;36mBaseTransform.__call__\u001b[0;34m(self, results)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[1;32m     10\u001b[0m              results: Dict) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Optional[Union[Dict, Tuple[List, List]]]:\n\u001b[0;32m---> 12\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(results)\n",
      "File \u001b[0;32m~/alvaro/sensus-loci/mmdetection3d/mmdet3d/datasets/transforms/test_time_aug.py:109\u001b[0m, in \u001b[0;36mMultiScaleFlipAug3D.transform\u001b[0;34m(self, results)\u001b[0m\n\u001b[1;32m    105\u001b[0m                         _results[\u001b[39m'\u001b[39m\u001b[39mpcd_horizontal_flip\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \\\n\u001b[1;32m    106\u001b[0m                             pcd_horizontal_flip\n\u001b[1;32m    107\u001b[0m                         _results[\u001b[39m'\u001b[39m\u001b[39mpcd_vertical_flip\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \\\n\u001b[1;32m    108\u001b[0m                             pcd_vertical_flip\n\u001b[0;32m--> 109\u001b[0m                         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransforms(_results)\n\u001b[1;32m    110\u001b[0m                         aug_data_list\u001b[39m.\u001b[39mappend(data)\n\u001b[1;32m    112\u001b[0m \u001b[39mreturn\u001b[39;00m aug_data_list\n",
      "File \u001b[0;32m~/anaconda3/envs/sensus_1.1/lib/python3.8/site-packages/mmengine/dataset/base_dataset.py:58\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[39m\"\"\"Call function to apply transforms sequentially.\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \n\u001b[1;32m     51\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39m   dict: Transformed data.\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[0;32m---> 58\u001b[0m     data \u001b[39m=\u001b[39m t(data)\n\u001b[1;32m     59\u001b[0m     \u001b[39m# The transform will return None when it failed to load images or\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[39m# cannot find suitable augmentation parameters to augment the data.\u001b[39;00m\n\u001b[1;32m     61\u001b[0m     \u001b[39m# Here we simply return None if the transform returns None and the\u001b[39;00m\n\u001b[1;32m     62\u001b[0m     \u001b[39m# dataset will handle it by randomly selecting another data sample.\u001b[39;00m\n\u001b[1;32m     63\u001b[0m     \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/sensus_1.1/lib/python3.8/site-packages/mmcv/transforms/base.py:12\u001b[0m, in \u001b[0;36mBaseTransform.__call__\u001b[0;34m(self, results)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[1;32m     10\u001b[0m              results: Dict) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Optional[Union[Dict, Tuple[List, List]]]:\n\u001b[0;32m---> 12\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(results)\n",
      "File \u001b[0;32m~/alvaro/sensus-loci/mmdetection3d/mmdet3d/datasets/transforms/transforms_3d.py:782\u001b[0m, in \u001b[0;36mGlobalRotScaleTrans.transform\u001b[0;34m(self, input_dict)\u001b[0m\n\u001b[1;32m    779\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mtransformation_3d_flow\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m input_dict:\n\u001b[1;32m    780\u001b[0m     input_dict[\u001b[39m'\u001b[39m\u001b[39mtransformation_3d_flow\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 782\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_rot_bbox_points(input_dict)\n\u001b[1;32m    784\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mpcd_scale_factor\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m input_dict:\n\u001b[1;32m    785\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_random_scale(input_dict)\n",
      "File \u001b[0;32m~/alvaro/sensus-loci/mmdetection3d/mmdet3d/datasets/transforms/transforms_3d.py:725\u001b[0m, in \u001b[0;36mGlobalRotScaleTrans._rot_bbox_points\u001b[0;34m(self, input_dict)\u001b[0m\n\u001b[1;32m    722\u001b[0m     input_dict[\u001b[39m'\u001b[39m\u001b[39mpoints\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m points\n\u001b[1;32m    723\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    724\u001b[0m     \u001b[39m# if no bbox in input_dict, only rotate points\u001b[39;00m\n\u001b[0;32m--> 725\u001b[0m     rot_mat_T \u001b[39m=\u001b[39m input_dict[\u001b[39m'\u001b[39;49m\u001b[39mpoints\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mrotate(noise_rotation)\n\u001b[1;32m    727\u001b[0m input_dict[\u001b[39m'\u001b[39m\u001b[39mpcd_rotation\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m rot_mat_T\n\u001b[1;32m    728\u001b[0m input_dict[\u001b[39m'\u001b[39m\u001b[39mpcd_rotation_angle\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m noise_rotation\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'rotate'"
     ]
    }
   ],
   "source": [
    "# Same result after processing points (maybe processing under the hood when\n",
    "# using np.array pc)\n",
    "points = points.reshape(-1, 4)\n",
    "result, data = inference_detector(model, points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
      "tensor([0.1304, 0.1173, 0.3624, 0.3572, 0.9088, 0.8917, 0.8498, 0.7471, 0.7245,\n",
      "        0.6414, 0.6307, 0.5603, 0.4316, 0.3937], device='cuda:0')\n",
      "torch.Size([14, 7])\n"
     ]
    }
   ],
   "source": [
    "print(result.pred_instances_3d.labels_3d)\n",
    "print(result.pred_instances_3d.scores_3d)\n",
    "print(result.pred_instances_3d.bboxes_3d.tensor.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_path = os.path.join(demo.__path__[0],\n",
    "    'data/kitti/000008.bin')\n",
    "pc_path = os.path.join(\n",
    "    '/home/messi/alvaro/sensus-loci/mmdetection3d/demo/kitti_pointpillars/kitti_000008',\n",
    "    'kitti_000008_points.obj')\n",
    "bboxes_path = os.path.join(\n",
    "    '/home/messi/alvaro/sensus-loci/mmdetection3d/demo/kitti_pointpillars/kitti_000008',\n",
    "    'kitti_000008_pred.obj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointCloud with 17238 points.\n"
     ]
    }
   ],
   "source": [
    "# Read pc from bin file\n",
    "with open(bin_path, 'rb') as f:\n",
    "    points = np.fromfile(f, dtype=np.float32, count=-1).reshape([-1, 4])\n",
    "\n",
    "pcd_bin = o3d.geometry.PointCloud()\n",
    "pcd_bin.points = o3d.utility.Vector3dVector(points[:, :3])\n",
    "print(pcd_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointCloud with 16897 points.\n",
      "LineSet with 360 lines.\n"
     ]
    }
   ],
   "source": [
    "# Read pc from obj file (reading with o3d.io.read_triangle_mesh or \n",
    "# read_point_cloud does not work)\n",
    "pc = []\n",
    "with open(pc_path, 'rb') as f:\n",
    "    for each in f.readlines():\n",
    "        p1, p2, p3 = each.decode('utf-8').split(' ')[1:]\n",
    "        pc.append([float(p1), float(p2), float(p3.replace('\\n', ''))])\n",
    "\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(np.array(pc))\n",
    "print(pcd)\n",
    "\n",
    "bboxes = o3d.io.read_triangle_mesh(bboxes_path)\n",
    "bboxes.compute_vertex_normals()     # For solid rendering with lighting\n",
    "bboxes_lines = o3d.geometry.LineSet().create_from_triangle_mesh(bboxes)\n",
    "bboxes_lines.paint_uniform_color([1, 0, 0])\n",
    "print(bboxes_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e26e88557d9481b915bb09e78724163",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "WebVisualizer(window_uid='window_11')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw([pcd, bboxes_lines], width=900, height=600, point_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf594293333b4974bb61a30edfe9f4bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "WebVisualizer(window_uid='window_0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw([pcd_bin, bboxes_lines], width=900, height=600, point_size=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sensus_1.1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f415ed57821a0a57975d366e83fa539ca7287180412c6dde381c2f215d5e4022"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
