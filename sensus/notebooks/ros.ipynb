{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2023-04-06 11:09:05,469 - instantiator - Created a temporary directory at /tmp/tmpdib22gz3\n",
      "INFO - 2023-04-06 11:09:05,470 - instantiator - Writing /tmp/tmpdib22gz3/_remote_module_non_scriptable.py\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Open3D INFO] Resetting default logger to print to terminal.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "import sensus\n",
    "\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "\n",
    "from sensus.utils.data_converter import pc2pc_object\n",
    "from open3d.web_visualizer import draw\n",
    "from mmdetection3d import data, demo, configs, checkpoints\n",
    "from sensus import configs as sensus_configs\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read pickle file lidar.pickle from data directory\n",
    "with open(os.path.join(sensus.__path__[0], 'data/lidar.pickle'), 'rb') as f:\n",
    "    lidar_pickle = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_buffer = np.frombuffer(lidar_pickle.data,\n",
    "                    dtype=[('x', np.float32), ('y', np.float32), ('z', np.float32), ('intensity', np.float32)],\n",
    "                    count=lidar_pickle.width*lidar_pickle.height, offset=0)\n",
    "pc_ros = pc_buffer.view(dtype=np.float32).reshape(pc_buffer.shape[0], -1)\n",
    "pc_ros[:, 2] = pc_ros[:, 2] + 4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmdet3d.apis import inference_detector, init_model\n",
    "from mmdet3d.utils import register_all_modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: /home/messi/alvaro/sensus-loci/mmdetection3d/checkpoints/centerpoint_0075voxel_second_secfpn_circlenms_4x8_cyclic_20e_nus_20220810_011659-04cb3a3b.pth\n"
     ]
    }
   ],
   "source": [
    "register_all_modules()\n",
    "# model_cfg = os.path.join(sensus_configs.__path__[0],\n",
    "#     'second/second_hv_secfpn_8xb6-80e_kitti-3d-3class-ros.py')\n",
    "model_cfg = os.path.join(configs.__path__[0],\n",
    "    'centerpoint/centerpoint_voxel0075_second_secfpn_head-circlenms_8xb4-cyclic-20e_nus-3d.py')\n",
    "# checkpoint_path = os.path.join(checkpoints.__path__[0],\n",
    "#     'hv_second_secfpn_6x8_80e_kitti-3d-3class_20210831_022017-ae782e87.pth')\n",
    "checkpoint_path = os.path.join(checkpoints.__path__[0],\n",
    "    'centerpoint_0075voxel_second_secfpn_circlenms_4x8_cyclic_20e_nus_20220810_011659-04cb3a3b.pth')\n",
    "device = 'cuda:0'\n",
    "\n",
    "model = init_model(model_cfg, checkpoint_path, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[115.05504    115.06092     -0.7852335    0.95542234]\n",
      "[-116.592995   -115.0505       -4.008335      0.61992574]\n"
     ]
    }
   ],
   "source": [
    "# Print the max and min values of each column in the point cloud\n",
    "print(np.max(pc_ros, axis=0))\n",
    "print(np.min(pc_ros, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'LoadPointsFromFile',\n",
       "  'coord_type': 'LIDAR',\n",
       "  'load_dim': 4,\n",
       "  'use_dim': 5},\n",
       " {'type': 'LoadPointsFromMultiSweeps',\n",
       "  'sweeps_num': 9,\n",
       "  'use_dim': [0, 1, 2, 3],\n",
       "  'pad_empty_sweeps': True,\n",
       "  'remove_close': True},\n",
       " {'type': 'MultiScaleFlipAug3D',\n",
       "  'img_scale': (1333, 800),\n",
       "  'pts_scale_ratio': 1,\n",
       "  'flip': False,\n",
       "  'transforms': [{'type': 'GlobalRotScaleTrans',\n",
       "    'rot_range': [0, 0],\n",
       "    'scale_ratio_range': [1.0, 1.0],\n",
       "    'translation_std': [0, 0, 0]},\n",
       "   {'type': 'RandomFlip3D'},\n",
       "   {'type': 'PointsRangeFilter',\n",
       "    'point_cloud_range': [-54, -54, -5.0, 54, 54, 3.0]}]},\n",
       " {'type': 'Pack3DDetInputs', 'keys': ['points']}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cfg.test_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/06 11:13:37 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The \"transform\" registry in mmdet3d did not set import location. Fallback to call `mmdet3d.utils.register_all_modules` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/messi/alvaro/sensus-loci/mmdetection3d/mmdet3d/models/task_modules/coders/centerpoint_bbox_coders.py:201: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.post_center_range = torch.tensor(\n",
      "/home/messi/alvaro/sensus-loci/mmdetection3d/mmdet3d/models/task_modules/coders/centerpoint_bbox_coders.py:201: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.post_center_range = torch.tensor(\n"
     ]
    }
   ],
   "source": [
    "# ROS\n",
    "pc_object_ros, _ = pc2pc_object(pc_ros.flatten(), model.cfg.test_pipeline)\n",
    "result_ros, _ = inference_detector(model, pc_object_ros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mmdet3d.structures.det3d_data_sample.Det3DDataSample"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result_ros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22.506675720214844, 28.6533203125, -3.9237818717956543, 4.577454566955566, 1.8992881774902344, 1.6064486503601074, 2.5990734100341797, -2.3876028060913086, 2.019270181655884]\n",
      "0.8311319351196289\n"
     ]
    }
   ],
   "source": [
    "for i, bbox_pred in enumerate(result_ros.pred_instances_3d.bboxes_3d.tensor.tolist()):\n",
    "    print(bbox_pred)\n",
    "    print(result_ros.pred_instances_3d.scores_3d[i].item())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 5]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_ros.pred_instances_3d.labels_3d.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.min(\n",
       "values=tensor([-32.6744, -36.7824,  -4.2120,   0.4797,   0.7362,   0.8834,  -3.0265,\n",
       "         -7.6658,  -9.6750], device='cuda:0'),\n",
       "indices=tensor([ 4, 17, 10, 22, 23, 21, 19, 11,  7], device='cuda:0'))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_ros.pred_instances_3d.bboxes_3d.tensor.min(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([37.5542, 31.8943,  0.0938, 17.5359,  3.1787,  4.2872,  3.1106,  6.4032,\n",
       "         6.4455], device='cuda:0'),\n",
       "indices=tensor([20, 10, 23, 20, 21, 20, 21, 15,  3], device='cuda:0'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_ros.pred_instances_3d.bboxes_3d.tensor.max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  1.6682, -37.9861,  -2.6241,   4.3703,   1.7161,   1.5333,   3.2115],\n",
      "       device='cuda:0')\n",
      "torch.Size([18, 7])\n"
     ]
    }
   ],
   "source": [
    "# print(result_ros.pred_instances_3d.labels_3d)\n",
    "# print(result_ros.pred_instances_3d.scores_3d)\n",
    "# print(result_ros.pred_instances_3d.bboxes_3d)\n",
    "print(result_ros.pred_instances_3d.bboxes_3d.tensor[0])\n",
    "print(result_ros.pred_instances_3d.bboxes_3d.tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'rotate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Same result after processing points (maybe processing under the hood when\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# using np.array pc)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m points \u001b[39m=\u001b[39m points\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m4\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m result, data \u001b[39m=\u001b[39m inference_detector(model, points)\n",
      "File \u001b[0;32m~/alvaro/sensus-loci/mmdetection3d/mmdet3d/apis/inference.py:158\u001b[0m, in \u001b[0;36minference_detector\u001b[0;34m(model, pcds)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    150\u001b[0m         \u001b[39m# directly use loaded point cloud\u001b[39;00m\n\u001b[1;32m    151\u001b[0m         data_ \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\n\u001b[1;32m    152\u001b[0m             points\u001b[39m=\u001b[39mpcd,\n\u001b[1;32m    153\u001b[0m             timestamp\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    156\u001b[0m             box_type_3d\u001b[39m=\u001b[39mbox_type_3d,\n\u001b[1;32m    157\u001b[0m             box_mode_3d\u001b[39m=\u001b[39mbox_mode_3d)\n\u001b[0;32m--> 158\u001b[0m     data_ \u001b[39m=\u001b[39m test_pipeline(data_)\n\u001b[1;32m    159\u001b[0m     data\u001b[39m.\u001b[39mappend(data_)\n\u001b[1;32m    161\u001b[0m collate_data \u001b[39m=\u001b[39m pseudo_collate(data)\n",
      "File \u001b[0;32m~/anaconda3/envs/sensus_1.1/lib/python3.8/site-packages/mmengine/dataset/base_dataset.py:58\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[39m\"\"\"Call function to apply transforms sequentially.\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \n\u001b[1;32m     51\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39m   dict: Transformed data.\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[0;32m---> 58\u001b[0m     data \u001b[39m=\u001b[39m t(data)\n\u001b[1;32m     59\u001b[0m     \u001b[39m# The transform will return None when it failed to load images or\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[39m# cannot find suitable augmentation parameters to augment the data.\u001b[39;00m\n\u001b[1;32m     61\u001b[0m     \u001b[39m# Here we simply return None if the transform returns None and the\u001b[39;00m\n\u001b[1;32m     62\u001b[0m     \u001b[39m# dataset will handle it by randomly selecting another data sample.\u001b[39;00m\n\u001b[1;32m     63\u001b[0m     \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/sensus_1.1/lib/python3.8/site-packages/mmcv/transforms/base.py:12\u001b[0m, in \u001b[0;36mBaseTransform.__call__\u001b[0;34m(self, results)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[1;32m     10\u001b[0m              results: Dict) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Optional[Union[Dict, Tuple[List, List]]]:\n\u001b[0;32m---> 12\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(results)\n",
      "File \u001b[0;32m~/alvaro/sensus-loci/mmdetection3d/mmdet3d/datasets/transforms/test_time_aug.py:109\u001b[0m, in \u001b[0;36mMultiScaleFlipAug3D.transform\u001b[0;34m(self, results)\u001b[0m\n\u001b[1;32m    105\u001b[0m                         _results[\u001b[39m'\u001b[39m\u001b[39mpcd_horizontal_flip\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \\\n\u001b[1;32m    106\u001b[0m                             pcd_horizontal_flip\n\u001b[1;32m    107\u001b[0m                         _results[\u001b[39m'\u001b[39m\u001b[39mpcd_vertical_flip\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \\\n\u001b[1;32m    108\u001b[0m                             pcd_vertical_flip\n\u001b[0;32m--> 109\u001b[0m                         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransforms(_results)\n\u001b[1;32m    110\u001b[0m                         aug_data_list\u001b[39m.\u001b[39mappend(data)\n\u001b[1;32m    112\u001b[0m \u001b[39mreturn\u001b[39;00m aug_data_list\n",
      "File \u001b[0;32m~/anaconda3/envs/sensus_1.1/lib/python3.8/site-packages/mmengine/dataset/base_dataset.py:58\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[39m\"\"\"Call function to apply transforms sequentially.\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \n\u001b[1;32m     51\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39m   dict: Transformed data.\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[0;32m---> 58\u001b[0m     data \u001b[39m=\u001b[39m t(data)\n\u001b[1;32m     59\u001b[0m     \u001b[39m# The transform will return None when it failed to load images or\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[39m# cannot find suitable augmentation parameters to augment the data.\u001b[39;00m\n\u001b[1;32m     61\u001b[0m     \u001b[39m# Here we simply return None if the transform returns None and the\u001b[39;00m\n\u001b[1;32m     62\u001b[0m     \u001b[39m# dataset will handle it by randomly selecting another data sample.\u001b[39;00m\n\u001b[1;32m     63\u001b[0m     \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/sensus_1.1/lib/python3.8/site-packages/mmcv/transforms/base.py:12\u001b[0m, in \u001b[0;36mBaseTransform.__call__\u001b[0;34m(self, results)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[1;32m     10\u001b[0m              results: Dict) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Optional[Union[Dict, Tuple[List, List]]]:\n\u001b[0;32m---> 12\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(results)\n",
      "File \u001b[0;32m~/alvaro/sensus-loci/mmdetection3d/mmdet3d/datasets/transforms/transforms_3d.py:782\u001b[0m, in \u001b[0;36mGlobalRotScaleTrans.transform\u001b[0;34m(self, input_dict)\u001b[0m\n\u001b[1;32m    779\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mtransformation_3d_flow\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m input_dict:\n\u001b[1;32m    780\u001b[0m     input_dict[\u001b[39m'\u001b[39m\u001b[39mtransformation_3d_flow\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 782\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_rot_bbox_points(input_dict)\n\u001b[1;32m    784\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mpcd_scale_factor\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m input_dict:\n\u001b[1;32m    785\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_random_scale(input_dict)\n",
      "File \u001b[0;32m~/alvaro/sensus-loci/mmdetection3d/mmdet3d/datasets/transforms/transforms_3d.py:725\u001b[0m, in \u001b[0;36mGlobalRotScaleTrans._rot_bbox_points\u001b[0;34m(self, input_dict)\u001b[0m\n\u001b[1;32m    722\u001b[0m     input_dict[\u001b[39m'\u001b[39m\u001b[39mpoints\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m points\n\u001b[1;32m    723\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    724\u001b[0m     \u001b[39m# if no bbox in input_dict, only rotate points\u001b[39;00m\n\u001b[0;32m--> 725\u001b[0m     rot_mat_T \u001b[39m=\u001b[39m input_dict[\u001b[39m'\u001b[39;49m\u001b[39mpoints\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mrotate(noise_rotation)\n\u001b[1;32m    727\u001b[0m input_dict[\u001b[39m'\u001b[39m\u001b[39mpcd_rotation\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m rot_mat_T\n\u001b[1;32m    728\u001b[0m input_dict[\u001b[39m'\u001b[39m\u001b[39mpcd_rotation_angle\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m noise_rotation\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'rotate'"
     ]
    }
   ],
   "source": [
    "# Same result after processing points (maybe processing under the hood when\n",
    "# using np.array pc)\n",
    "points = points.reshape(-1, 4)\n",
    "result, data = inference_detector(model, points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
      "tensor([0.1304, 0.1173, 0.3624, 0.3572, 0.9088, 0.8917, 0.8498, 0.7471, 0.7245,\n",
      "        0.6414, 0.6307, 0.5603, 0.4316, 0.3937], device='cuda:0')\n",
      "torch.Size([14, 7])\n"
     ]
    }
   ],
   "source": [
    "print(result.pred_instances_3d.labels_3d)\n",
    "print(result.pred_instances_3d.scores_3d)\n",
    "print(result.pred_instances_3d.bboxes_3d.tensor.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_path = os.path.join(demo.__path__[0],\n",
    "    'data/kitti/000008.bin')\n",
    "pc_path = os.path.join(\n",
    "    '/home/messi/alvaro/sensus-loci/mmdetection3d/demo/kitti_pointpillars/kitti_000008',\n",
    "    'kitti_000008_points.obj')\n",
    "bboxes_path = os.path.join(\n",
    "    '/home/messi/alvaro/sensus-loci/mmdetection3d/demo/kitti_pointpillars/kitti_000008',\n",
    "    'kitti_000008_pred.obj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointCloud with 17238 points.\n"
     ]
    }
   ],
   "source": [
    "# Read pc from bin file\n",
    "with open(bin_path, 'rb') as f:\n",
    "    points = np.fromfile(f, dtype=np.float32, count=-1).reshape([-1, 4])\n",
    "\n",
    "pcd_bin = o3d.geometry.PointCloud()\n",
    "pcd_bin.points = o3d.utility.Vector3dVector(points[:, :3])\n",
    "print(pcd_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointCloud with 16897 points.\n",
      "LineSet with 360 lines.\n"
     ]
    }
   ],
   "source": [
    "# Read pc from obj file (reading with o3d.io.read_triangle_mesh or \n",
    "# read_point_cloud does not work)\n",
    "pc = []\n",
    "with open(pc_path, 'rb') as f:\n",
    "    for each in f.readlines():\n",
    "        p1, p2, p3 = each.decode('utf-8').split(' ')[1:]\n",
    "        pc.append([float(p1), float(p2), float(p3.replace('\\n', ''))])\n",
    "\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(np.array(pc))\n",
    "print(pcd)\n",
    "\n",
    "bboxes = o3d.io.read_triangle_mesh(bboxes_path)\n",
    "bboxes.compute_vertex_normals()     # For solid rendering with lighting\n",
    "bboxes_lines = o3d.geometry.LineSet().create_from_triangle_mesh(bboxes)\n",
    "bboxes_lines.paint_uniform_color([1, 0, 0])\n",
    "print(bboxes_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e26e88557d9481b915bb09e78724163",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "WebVisualizer(window_uid='window_11')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw([pcd, bboxes_lines], width=900, height=600, point_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf594293333b4974bb61a30edfe9f4bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "WebVisualizer(window_uid='window_0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw([pcd_bin, bboxes_lines], width=900, height=600, point_size=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sensus_1.1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f415ed57821a0a57975d366e83fa539ca7287180412c6dde381c2f215d5e4022"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
